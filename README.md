This text summarization project was done as a part of Natural Language Processing Course at IIITD. It uses Bart model for the task of summarization.

The english dataset for testing and training was taken from the ILSUM2023 : TASK-1 ( website link : https://ilsum.github.io/ilsum/2023/dataset.html )

BART model was used by us, we tried exploring other models like T5, but they didn't work very well. and the PEGASUS model which might have worked well has a really big architecture and requires high amount of resources.
We trained the model for 3 epochs, model performance can be further improved by training it for more epochs (7 to 10) and tuning other hyperparameters.

for the saved model checkpoint, testing and training data, i am attaching a drive link : https://drive.google.com/drive/folders/13jnnZ-ATYj3WQNd8fpJFaaNSz9yc7Vwv?usp=sharing

Thanks!
